{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn import metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import mixture\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import HeatMap\n",
    "from folium.plugins import MeasureControl\n",
    "from folium.plugins import Fullscreen\n",
    "from folium.plugins import FastMarkerCluster\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "\n",
    "from functools import reduce\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "'''\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense, Dropout, Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# reviews = pd.read_csv('input/yelp_review.csv') # will take over 2 minutes\n",
    "reviews = pd.read_csv('input/yelp_review.csv', nrows=10000) # essentially instant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "businesses = pd.read_csv('input/yelp_business.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "attributes = pd.read_csv('input/yelp_business_attributes.csv', \n",
    "                             dtype='category', na_values='Na', true_values='True', false_values='False')\n",
    "attribute_names = attributes.drop('business_id', axis=1).columns\n",
    "attributes[attribute_names] = attributes[attribute_names].apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = businesses.merge(attributes, on='business_id').set_index('business_id')\n",
    "joined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA analysis for the attributes database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_atts = pd.Series([int(x) for x in joined['stars']]) #round star ratings\n",
    "x_atts = joined[joined.columns[12:]] #all the business attributes\n",
    "x_atts_train, x_atts_dev, y_atts_train, y_atts_dev = train_test_split(x_atts, y_atts, test_size=.2, random_state=0)\n",
    "pca = PCA()\n",
    "pca.fit(x_atts_train)\n",
    "print('Explained variance by component')\n",
    "plt.bar(height = pca.explained_variance_ratio_[0:50], x = list(range(1,51)))\n",
    "plt.show()\n",
    "accrued = []\n",
    "print()\n",
    "print('Explained variance up to...')\n",
    "for k in range(1,51):\n",
    "    accrued.append(reduce(lambda x,y: x + y, pca.explained_variance_ratio_[0:k]))\n",
    "plt.bar(height = accrued, x = list(range(1,51)))    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I'm gonna check the factor loadings. If I have m components and p features, then this pxm matrix is the covariance between my feature matrix and my principal components. This way we can check which attributes are correlated with the most important components and get a proxy of which features are most important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 6)\n",
    "pca.fit(x_atts_train)\n",
    "factor_loadings = pca.components_.T*np.sqrt(pca.explained_variance_)\n",
    "print('Graphic representation of the attributes more correlated with the component factors')\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(factor_loadings.T, cmap='gray', interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fl = pd.DataFrame(factor_loadings, index = x_atts.columns.values, columns = range(1,7))\n",
    "print('Ten most important attributes')\n",
    "print(df_fl.applymap(abs).mean(axis = 1).sort_values(ascending = False)[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 3)\n",
    "td = pca.fit_transform(x_atts_train)\n",
    "star_1 = td[y_atts_train == 1]\n",
    "star_2 = td[y_atts_train == 2]\n",
    "star_3 = td[y_atts_train == 3]\n",
    "star_4 = td[y_atts_train == 4]\n",
    "star_5 = td[y_atts_train == 5]\n",
    "print(star_1.shape[0]+star_2.shape[0]+star_3.shape[0]+star_4.shape[0]+star_5.shape[0]-td.shape[0]) #check that calculations are correct\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for c, m, star in [('r', 'o', star_1), ('g', '^', star_2), ('b', 'o', star_3), ('c', '^', star_4), ('m', '^', star_5)]:\n",
    "    xs = star[:,0]\n",
    "    ys = star[:,1]\n",
    "    zs = star[:,2]\n",
    "    ax.scatter(xs, ys, zs, c=c, marker=m, s=5, zdir = 'x')\n",
    "\n",
    "ax.set_xlabel('First component')\n",
    "ax.set_ylabel('Second component')\n",
    "ax.set_zlabel('Third component')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for c, m, star in [('b', 'o', star_1), ('r', 'o', star_5)]:\n",
    "    xs = star[:,0]\n",
    "    ys = star[:,1]\n",
    "    zs = star[:,2]\n",
    "    ax.scatter(xs, ys, zs, c=c, marker=m, s=20, zdir = 'x')\n",
    "\n",
    "ax.set_xlabel('First component')\n",
    "ax.set_ylabel('Second component')\n",
    "ax.set_zlabel('Third component')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually, it doesn't seems that there's a way to separate the star rating by the content of the attributes. But it could be that there is a solution in higher dimensions or using non linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive model using only PCA components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian mixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data will be binarized by setting 1-2 as 1 and 4-5 as 5, 3s are dropped from the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_mat = ['spherical', 'diag', 'tied', 'full']\n",
    "n_GMM = [6,4,3,2]\n",
    "acc = []\n",
    "y_atts_dev = y_atts_dev.reset_index(drop = True)\n",
    "x_atts_dev = x_atts_dev.reset_index(drop = True)\n",
    "bin_y_atts_dev = y_atts_dev[(y_atts_dev<3) | (y_atts_dev>3)].apply(lambda x: 1 if x <3 else 5)\n",
    "bin_x_atts_dev = x_atts_dev[(y_atts_dev<3) | (y_atts_dev>3)]\n",
    "\n",
    "for k in range(0,len(cov_mat)):\n",
    "    for i in range(0,len(n_GMM)):\n",
    "        pca = PCA(n_components = 6)\n",
    "        td = pca.fit_transform(x_atts_train)\n",
    "        neg = td[y_atts_train < 3]\n",
    "        pos = td[y_atts_train > 3]\n",
    "        tst = pca.fit_transform(bin_x_atts_dev)\n",
    "        clf = mixture.GaussianMixture(n_components = n_GMM[i], covariance_type = cov_mat[k], random_state = 0)\n",
    "        clf_td_pos = clf.fit(pos)\n",
    "        tst_mat_pos = np.exp(clf_td_pos.score_samples(tst))\n",
    "        clf_td_neg = clf.fit(neg)\n",
    "        tst_mat_neg = np.exp(clf_td_neg.score_samples(tst))\n",
    "        y_pred = [5 if tst_mat_pos[j] > tst_mat_neg[j] else 1 for j in range(0,len(tst_mat_pos))]\n",
    "        num = [1 if y_pred[j] == bin_y_atts_dev.iloc[j] else 0 for j in range(0,len(y_pred))]\n",
    "        acc.append(sum(num)/len(y_pred))\n",
    "mx = acc.index(max(acc))\n",
    "a = mx//4\n",
    "b = mx-a*4\n",
    "print('Maximum accuracy was ', acc[mx], \"\\n\", \"It was achieved using 6 PCA components, \", n_GMM[b], \" GMM components, with a \", cov_mat[a], \" covariance matrix.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using all labels\n",
    "print('All labels')\n",
    "svc = LinearSVC()\n",
    "svc.fit(td, y_atts_train)\n",
    "tst = pca.fit_transform(x_atts_dev)\n",
    "print(metrics.classification_report(y_atts_dev, svc.predict(tst)))\n",
    "print()\n",
    "print('Binarized data')\n",
    "bin_td = td[(y_atts_train<3) | (y_atts_train>3)]\n",
    "bin_y_atts_train = y_atts_train[(y_atts_train<3) | (y_atts_train>3)].apply(lambda x: 1 if x <3 else 5)\n",
    "svc.fit(bin_td, bin_y_atts_train)\n",
    "bin_tst = pca.fit_transform(bin_x_atts_dev)\n",
    "print(metrics.classification_report(bin_y_atts_dev, svc.predict(bin_tst)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(td, y_atts_train)\n",
    "y_pred = gnb.predict(tst)\n",
    "print(\"Classification report for GaussianNB - All labels\")\n",
    "print(metrics.classification_report(y_atts_dev,y_pred))\n",
    "gnb = gnb.fit(bin_td, bin_y_atts_train)\n",
    "y_pred = gnb.predict(bin_tst)\n",
    "print(\"Classification report for GaussianNB - Binarized data\")\n",
    "print(metrics.classification_report(bin_y_atts_dev,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(td, y_atts_train)\n",
    "print(\"Classification report for Decision Tree - All labels\")\n",
    "print(metrics.classification_report(y_atts_dev, dt.predict(tst)))\n",
    "dt.fit(bin_td, bin_y_atts_train)\n",
    "print(\"Classification report for Decision Tree - Binarized data\")\n",
    "print(metrics.classification_report(bin_y_atts_dev, dt.predict(bin_tst)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(td, y_atts_train)\n",
    "print(\"Classification report for Random Forest - All labels\")\n",
    "print(metrics.classification_report(y_atts_dev, rf.predict(tst)))\n",
    "rf.fit(bin_td, bin_y_atts_train)\n",
    "print(\"Classification report for Random Forest - Binarized data\")\n",
    "print(metrics.classification_report(bin_y_atts_dev, rf.predict(bin_tst)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lr = LogisticRegression(penalty='l1', C=2)\n",
    "lr.fit(td, y_atts_train)\n",
    "print(\"Classification report for Logistic regression - All labels\")\n",
    "print(metrics.classification_report(y_atts_dev, lr.predict(tst)))\n",
    "lr.fit(bin_td, bin_y_atts_train)\n",
    "print(\"Classification report for Logistic regression - Binarized data\")\n",
    "print(metrics.classification_report(bin_y_atts_dev, lr.predict(bin_tst)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of Sergio's section, this will look a lot more organized when we merge the different bits of code..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting the supervised machine learning, let us do some basic exploratory data analysis.  First let's take a look at what information we have in the `reviews` data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.countplot('stars', data=reviews)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some right skew in the star ratings.  We will leave this alone for now and come back to it in the **Predicting Stars with Review Text** section.  For geographical separation, we run KMeans and visualize on maps in the last section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to join businesses and attributes now.  Businesses without listed attributes and the converse will be excluded by the inner join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "joined = businesses.merge(attributes, on='business_id').set_index('business_id')\n",
    "joined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categories in the `businesses` data frame is useful to us.  However, it is currently in the form of semicolon separated values.  In addition, the categories for each business do not seem to be ordered in any way.  Consider that restaurants are probably the most popular type of business on Yelp, but the \"restaurant\" label is not necessarily first (or even near the top) of the category list for any given applicable business.  Therefore, we will do some preprocessing to extract all the categories and sort them by popularity, i.e. frequency of appearance in businesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter()\n",
    "joined.categories.str.split(';').apply(lambda x: c.update(x))\n",
    "\n",
    "print('Total number of business: %d' % joined.shape[0])\n",
    "\n",
    "n_categories = len(c.keys())\n",
    "print('Total number of categories: %d' % n_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = pd.DataFrame.from_dict(c, orient='index').reset_index()\n",
    "categories.columns = ['category', 'count']\n",
    "categories = categories.sort_values('count', ascending=False)\n",
    "\n",
    "plt.figure(figsize=[20,10])\n",
    "sns.barplot(x='category', y='count', data=categories.iloc[:10])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, the most popular category is restaurants by quite a large margin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to pull out the first few categories as \"main categories for each business.  To do this, we\n",
    "\n",
    "1. Split the categories\n",
    "2. Sort the categories by descending count\n",
    "3. Rejoin the categories\n",
    "4. Split the categories into separate columns\n",
    "5. Extract the first 3 columns\n",
    "\n",
    "Admitedly, there seems to be some inefficiency between steps 3 and 4.  I am currently unsure of how to do it better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_categories = joined.categories.str.split(';')\\\n",
    "    .apply(lambda row: ';'.join(sorted(row, key=lambda x:-c[x]))).\\\n",
    "    str.split(';', expand=True)\\\n",
    "    [[0,1,2]]\n",
    "\n",
    "main_categories.columns = ['category1', 'category2', 'category3']\n",
    "attributes_categories = pd.concat([joined, main_categories], axis=1)\n",
    "attributes_categories.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Stars with Business Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start our supervised learning first with exploring the possibility of predicting business ratings with its attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X_train_attr, X_test_attr, y_train_attr, y_test_attr = \\\n",
    "    train_test_split(joined[attribute_names].values, joined.stars.astype(np.int8).values, test_size=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train_attr, y_train_attr)\n",
    "\n",
    "print(metrics.classification_report(y_test_attr, dt.predict(X_test_attr), digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_attr, y_train_attr)\n",
    "\n",
    "print(metrics.classification_report(y_test_attr, rf.predict(X_test_attr), digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_attr+1, y_train_attr) # have to add 1 to X_train_attr because NB doesn't like negative numbers\n",
    "\n",
    "print(metrics.classification_report(y_test_attr, nb.predict(X_test_attr+1), digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Stars with Review Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will predict the star rating associated with each review text.  First, here is some reminder of what the reviews look like overall.  Recall that this data from only the first 10000 rows of data.  However, we have no reason to believe that the entire reviews dataset is not homogeneous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.countplot(reviews.stars)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print('Mean star rating: %.2f' % reviews.stars.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Star ratings tend to be skewed left and the average star rating is 3.74.  If humans were better at rating things objectively, we'd expect an average star rating around 2.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reviews['word_count'] = reviews.text.str.split().apply(len)\n",
    "\n",
    "sns.distplot(reviews.word_count, kde=False)\n",
    "plt.xlabel('Review Length')\n",
    "plt.ylabel('Count')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print('Mean review length: %.2f' % reviews.word_count.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, review lengths are skewed right.  Most people are just leaving short blurbs, while a select emotioned individuals are writing essays.  Let's take a look at an example of a review from each star rating.  We'll just look at short ones for now, so we don't have to read any of the aforementioned essays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_random_review(star, max_length=150):\n",
    "    return reviews[(reviews.stars == star) & (reviews.word_count < max_length)].sample(1).text.values[0]\n",
    "\n",
    "np.random.seed(4)\n",
    "for star in range(1,6):\n",
    "    print('%d star review:' % star)\n",
    "    print(get_random_review(star))\n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it is really not easy even for a human to discern between some of these reviews.  The difference between 1- and 5- star reviews is fairly obvious, but much less so between 2- and 3- or 3- and 4- star reviews.  Thus, we must temper our expectations for any machine learning algorithm accuracy.\n",
    "\n",
    "Now we will split the data up to start on our algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X_train_review, X_test_review, y_train_review, y_test_review = \\\n",
    "    train_test_split(reviews.text.values, reviews.stars.values, test_size=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with both a count vectorizer and a TFIDF vectorizer and compare the results using a simple logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "dtm_train = cv.fit_transform(X_train_review)\n",
    "dtm_test = cv.transform(X_test_review)\n",
    "print('Number of features from CountVectorizer: %d' % len(cv.get_feature_names()))\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(dtm_train, y_train_review)\n",
    "\n",
    "print(metrics.classification_report(y_test_review, lr.predict(dtm_test), digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tv = TfidfVectorizer(stop_words='english')\n",
    "dtm_train2 = tv.fit_transform(X_train_review)\n",
    "dtm_test2 = tv.transform(X_test_review)\n",
    "print('Number of features from TFIDFVectorizer: %d' % len(tv.get_feature_names()))\n",
    "\n",
    "lr2 = LogisticRegression()\n",
    "lr2.fit(dtm_train2, y_train_review)\n",
    "\n",
    "print(metrics.classification_report(y_test_review, lr2.predict(dtm_test), digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFIDF has both a better F1 score and is faster.  We will continue just using TFIDF instead of keeping two vectorizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rename some variables\n",
    "dtm_train = dtm_train2\n",
    "dtm_test = dtm_test2\n",
    "lr = lr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizing Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now do some searching for the best parameters for logistic regression in order to maximize accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lr = GridSearchCV(LogisticRegression(), {'penalty':['l1', 'l2'], 'C': [.02, .2, 2]})\n",
    "lr.fit(dtm_train, y_train_review)\n",
    "print('\\nLogistic Regression, best parameters: ' + str(lr.best_params_))\n",
    "print(metrics.classification_report(y_test_review, lr.predict(dtm_test), digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we explore an support vector classifier in place of a logistic regression one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a linear SVC as the C-support SVC scales quadratically with training size, making it unfeasible to train on the entire reviews set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "svc = LinearSVC()\n",
    "svc.fit(dtm_train, y_train_review)\n",
    "print(metrics.classification_report(y_test_review, svc.predict(dtm_test), digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "svc = GridSearchCV(LinearSVC(), {'C': [.02, .2, 2]})\n",
    "svc.fit(dtm_train, y_train_review)\n",
    "print('\\nSVC, best parameters: ' + str(svc.best_params_))\n",
    "print(metrics.classification_report(y_test_review, svc.predict(dtm_test), digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVC performs slightly worse than logistic regression, but trains faster.\n",
    "\n",
    "Naive Bayes is next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "nb = MultinomialNB()\n",
    "nb.fit(dtm_train, y_train_review)\n",
    "print(metrics.classification_report(y_test_review, nb.predict(dtm_test), digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "nb = GridSearchCV(MultinomialNB(), {'alpha': [.002, .02, .2, 2]})\n",
    "nb.fit(dtm_train, y_train_review)\n",
    "print('\\nMultinomial Naive Bayes, best parameters: ' + str(nb.best_params_))\n",
    "print(metrics.classification_report(y_test_review, nb.predict(dtm_test), digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes works really poorly unless we decrease Laplace smoothing (default value is 1).  Even then, it performs significantly worse than SVC or logistic regression albeit at a much faster training time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarizing the Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be difficult for even a human to perfectly predict a review's star rating just from the text.  This is especially true for the middle star ratings, where language may be less dramatic.  Therefore, we will now divide all the reviews into two categories (negative and positive) and see how well machine learning can differentiate between the two.\n",
    "\n",
    "We are going to filter out the 3 star reviews.  Then, we treat the 1- and 2-star reviews as negative; the 4- and 5-star reviews as positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extreme_reviews = reviews[['text', 'stars']][reviews.stars != 3]\n",
    "extreme_reviews['positive'] = extreme_reviews.stars > 3\n",
    "extreme_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('stars', data=extreme_reviews)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train the classifiers using the best parameters found in the previous sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X_train_review, X_test_review, y_train_review, y_test_review = \\\n",
    "    train_test_split(extreme_reviews.text.values, extreme_reviews.positive.values, test_size=.1)\n",
    "    \n",
    "tv = TfidfVectorizer(stop_words='english')\n",
    "dtm_train = tv.fit_transform(X_train_review)\n",
    "dtm_test = tv.transform(X_test_review)\n",
    "print('Number of features from TFIDFVectorizer: %d' % len(tv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lr = LogisticRegression(penalty='l1', C=2)\n",
    "lr.fit(dtm_train, y_train_review)\n",
    "\n",
    "print(metrics.classification_report(y_test_review, lr.predict(dtm_test), digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "svc = LinearSVC(C=.2)\n",
    "svc.fit(dtm_train, y_train_review)\n",
    "\n",
    "print(metrics.classification_report(y_test_review, svc.predict(dtm_test), digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "nb = MultinomialNB(alpha=.02)\n",
    "nb.fit(dtm_train, y_train_review)\n",
    "\n",
    "print(metrics.classification_report(y_test_review, nb.predict(dtm_test), digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected performance is now much better.  The algorithm is able to tell the difference between positive and negative reviews with over 90% accuracy in the case of logistic regression.  Logistic regression seems to be performing the best among the three candidate models, so we will continue with that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing the Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a classifier picked out, we will revisit the vectorizer to see if we can get any improvements by adjusting the paramenters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words='english')), \n",
    "    ('clf', LogisticRegression(penalty='l1', C=2))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'vect__ngram_range': [(1,1), (1,2)],\n",
    "    'vect__max_df': [.25, .4, .8, 1.0],\n",
    "    'vect__min_df': [0.0, .1, .2]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid)\n",
    "grid.fit(X_train_review, y_train_review)\n",
    "print('\\nBest parameters: ' + str(grid.best_params_))\n",
    "#print(grid.grid_scores_)\n",
    "print(metrics.classification_report(y_test_review, grid.predict(X_test_review), digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we did did not get any noticeable improvement in F1.  However, we were able to get this score with with the maximum document frequency set 0.4.  That means we are ignoring the top *60%* of the most frequent words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can push some more performance out by stemming the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "def stem(s):\n",
    "    return ' '.join(ps.stem(x) for x in s.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tv_stem = TfidfVectorizer(stop_words='english', max_df=.4)\n",
    "dtm_train_stem = tv_stem.fit_transform(map(stem, X_train_review))\n",
    "dtm_test_stem = tv_stem.transform(map(stem, X_test_review))\n",
    "print('Number of features from CountVectorizer: %d' % len(tv.vocabulary_))\n",
    "\n",
    "lr_stem = LogisticRegression(penalty='l1', C=2)\n",
    "lr_stem.fit(dtm_train_stem, y_train_review)\n",
    "\n",
    "print(metrics.classification_report(y_test_review, lr_stem.predict(dtm_test_stem), digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, it looks like stemming did not help in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Are we Actually Missing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the worst mistakes that the classifier is making see if we can't at least give some reason as to the mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_examples = 5\n",
    "\n",
    "pred = lr.predict(dtm_test)\n",
    "prob = lr.predict_proba(dtm_test)\n",
    "R = [(i, max(prob[i]), min(prob[i])) for i, y in enumerate(y_test_review) if y != pred[i]]\n",
    "R.sort(key=lambda x: -x[1]/x[2])\n",
    "\n",
    "for _ in range(num_examples):\n",
    "    for (i, wrong_prob, right_prob) in R:\n",
    "        if not num_examples: break\n",
    "        num_examples -= 1\n",
    "        \n",
    "        print('Index:', i)\n",
    "        print('Negative review probability: %3f' % prob[i][0])\n",
    "        print('Positive review probability: %3f' % prob[i][1])\n",
    "        print('\\n')\n",
    "        print(X_test_review[i])\n",
    "        print('\\n\\n\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice a lot of mistakes for reviews where the reviewer's expectation is stated but was not met.  We also see some language that may be hard to pick up by a machine learning algorithm (e.g. \"did not like\" is actually negative despite having the word \"like\" in it).  It seems that we need some sort of an algorithm that has a memory of what came before and after certain features.  Something like a recurrent neural network..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will implement a very simple recurrent neural network.  It will consist only 4 layers:\n",
    "1. An embedding layer for an efficient representation of the training samples\n",
    "2. A long short term memory layer for the bulk of the prediction power\n",
    "3. A dropout layer for regularization\n",
    "4. An output layer\n",
    "\n",
    "We will also have a checkpoint callback for saving the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But first, we need to tokenize the input.  We will use the same number of features as the vocabulary from the TFIDF vectorizer. Also we will only use the first 200 words from each review in order to capture most of the reviews, whilte setting a reasonable limit (recall the below plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(reviews.word_count, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = len(tv.vocabulary_) # use same number of features as TFIDF vectorizer\n",
    "maxlen = 200 # max words from each review to use\n",
    "\n",
    "t = Tokenizer(num_words=max_features)\n",
    "t.fit_on_texts(extreme_reviews['text'])\n",
    "texts = pad_sequences(t.texts_to_sequences(extreme_reviews['text']), maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build the model as described above.  We are essentially using the suggested LSTM network suggested [here](https://keras.io/getting-started/sequential-model-guide/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "try: model.load_weights('rnn_weights.hdf5') # load weights if they exist\n",
    "except: pass\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint(monitor='val_loss', save_best_only=True, filepath='rnn_weights.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create some new training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_rnn, X_test_rnn, y_train_rnn, y_test_rnn = \\\n",
    "    train_test_split(texts, extreme_reviews.positive.values, test_size=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model and output the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train_rnn, y_train_rnn, epochs=10, batch_size=64, callbacks=[checkpoint], validation_split=.1)\n",
    "\n",
    "print('Test')\n",
    "score = model.evaluate(X_test_rnn, y_test_rnn, batch_size=64)\n",
    "print('Loss = %.4f' % score[0])\n",
    "print('Accuracy = %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After quite a long time of training, we end up with performance that is not even as good as naive Bayes.  This is probably an artifact of the simplicity of the model.  Also we are not using very much training data here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load more data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we load some more data (10X what we've been developing with) and see how that affects the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "more_reviews = pd.read_csv('input/yelp_review.csv', nrows=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "more_reviews['positive'] = more_reviews.stars > 3\n",
    "\n",
    "np.random.seed(0)\n",
    "X_train_review2, X_test_review2, y_train_review2, y_test_review2 = \\\n",
    "    train_test_split(more_reviews.text.values, more_reviews.positive.values, test_size=.1)\n",
    "    \n",
    "tv = TfidfVectorizer(stop_words='english')\n",
    "dtm_train2 = tv.fit_transform(X_train_review2)\n",
    "dtm_test2 = tv.transform(X_test_review2)\n",
    "print('Number of features from TFIDFVectorizer: %d' % len(tv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lr = LogisticRegression(penalty='l1', C=2)\n",
    "lr.fit(dtm_train2, y_train_review2)\n",
    "\n",
    "print(metrics.classification_report(y_test_review2, lr.predict(dtm_test2), digits=3))\n",
    "print('Accuracy:', metrics.accuracy_score(y_test_review2, lr.predict(dtm_test2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_features = 26985 # use same number of features as previous TFIDF vectorizer\n",
    "maxlen = 200 # max words from each review to use\n",
    "\n",
    "t = Tokenizer(num_words=max_features)\n",
    "t.fit_on_texts(more_reviews['text'])\n",
    "texts = pad_sequences(t.texts_to_sequences(more_reviews['text']), maxlen = maxlen)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "try: model.load_weights('rnn_weights.hdf5') # load weights if they exist\n",
    "except: pass\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint(monitor='val_loss', save_best_only=True, filepath='rnn_weights.hdf5')\n",
    "\n",
    "X_train_rnn2, X_test_rnn2, y_train_rnn2, y_test_rnn2 = \\\n",
    "    train_test_split(texts, more_reviews.positive.values, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_rnn2, y_train_rnn2, epochs=10, batch_size=64, callbacks=[checkpoint], validation_split=.1)\n",
    "\n",
    "print('Test')\n",
    "score = model.evaluate(X_test_rnn2, y_test_rnn2, batch_size=64)\n",
    "print('Loss = %.4f' % score[0])\n",
    "print('Accuracy = %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately we did not improve the accuracy on the logistic regression or neural network model.  Some work needs to be done on the structure of the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning - Kmeans\n",
    "\n",
    "Treating the data given in yelp datasets as unlabelled (i.e. input variables(X) are given with no corresponding output variables), we apply Kmeans as an unsupervised learning algorithm to identify clusters of examples from business attributes to explore other structures in the data, particularly geographically significant structures.  The rationale for location based exploration of yelp reviews is the assumption that reviews depend on location factors, such as other nearby businesses and capital costs. First we explore geographic features of businesses according to their star ratings, median home price in the area the business operates and the number of reviews receive. Second we explore clusters by business attributes in the yelp dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_scaler(df):\n",
    "    '''\n",
    "    Preprocesses dataframe to normalize values before applying kmeans\n",
    "    '''\n",
    "    cols = df.columns\n",
    "    df = df.fillna(1)\n",
    "    x = df.values #returns a numpy array\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    x_scaled = scaler.fit_transform(x)\n",
    "    df = pd.DataFrame(x_scaled)\n",
    "    df.columns = cols\n",
    "    return df\n",
    "\n",
    "def elbow_chart(df,clust_test):\n",
    "    '''\n",
    "    Displays the elbow for selecting the right n for kmeans\n",
    "    Takes a numeric data frame runs kmeans through range in clust_test parameter\n",
    "    '''\n",
    "    error = np.zeros(clust_test+1)\n",
    "    error[0] = 0;\n",
    "    for k in range(1,clust_test+1):\n",
    "        kmeans = KMeans(init='k-means++', n_clusters=k, n_init=10)\n",
    "        kmeans.fit_predict(df)\n",
    "        error[k] = kmeans.inertia_\n",
    "    plt.figure(1)\n",
    "    plt.plot(range(1,len(error)),error[1:])\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Error')\n",
    "    plt.show()\n",
    "    return error\n",
    "\n",
    "# Geographic data processing\n",
    "def city_bbox(df,city_name):    \n",
    "    '''takes dataframe and makes bounding box according to density of reviews, and returns a df subset by city'''\n",
    "    df = df.query('city == \"{}\"'.format(city_name))\n",
    "    city_df = df[(df.latitude < df.latitude.mean() + df.latitude.std(0)) \n",
    "& (df.latitude >  df.latitude.mean() - df.latitude.std(0))\n",
    "& (df.longitude < df.longitude.mean() + cen*df.longitude.std(0))\n",
    "& (df.longitude >  df.longitude.mean() - cen*df.longitude.std(0))]\n",
    "    return city_df\n",
    "\n",
    "def pre_process_by_city(df,city_name,feature_lst):\n",
    "    '''\n",
    "    takes city, city name, and a list of features as arguments and returns X for kmeans\n",
    "    '''\n",
    "    c = df.query('city == \"{}\"'.format(city_name))\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    num_c = c.select_dtypes(include=numerics)\n",
    "    X = feature_scaler(num_c)\n",
    "    X = X[feature_lst] # 'longitude','latitude']\n",
    "    return X\n",
    "\n",
    "def city_clusters(df,city_name,feature_lst):\n",
    "    '''takes a dataframe, city name, and returns kmeans labels and cluster centers'''\n",
    "    X = pre_process_by_city(df,city_name,feature_lst)\n",
    "    kmeans = KMeans(n_clusters=4, random_state=0).fit(X)\n",
    "    return kmeans.labels_, kmeans.cluster_centers_\n",
    "\n",
    "def map_it(df,zoom,sample):\n",
    "    \n",
    "    '''\n",
    "    df = dataframe with 'latitude' and 'longitude' columns\n",
    "    sample = size of coordinates to sample\n",
    "    '''\n",
    "    mapcenter = [df.latitude.mean(), df.longitude.mean()]\n",
    "    p = folium.Map(location=mapcenter,\n",
    "                            tiles = \"Stamen Toner\",\n",
    "                            zoom_start = zoom) \n",
    "    p.add_child(MeasureControl())\n",
    "    plugins.Fullscreen(\n",
    "        position='topright',\n",
    "        title='Expand me',\n",
    "        title_cancel='Exit me',\n",
    "        force_separate_button=True).add_to(p)\n",
    "    # Ensure you're handing it floats\n",
    "    df['latitude'] = df['latitude'].astype(float)\n",
    "    df['longitude'] = df['longitude'].astype(float)\n",
    "    # Filter the DF for rows, then columns, then remove NaNs\n",
    "    heat_df = df.sample(sample)\n",
    "    heat_df = heat_df[['latitude', 'longitude']]\n",
    "    heat_df = heat_df.dropna(axis=0, subset=['latitude','longitude'])\n",
    "    # List comprehension to make out list of lists\n",
    "    heat_data = [[row['latitude'],row['longitude']] for index, row in heat_df.iterrows()]\n",
    "    # Plot it on the map\n",
    "    HeatMap(heat_data).add_to(p)\n",
    "    # Display the map\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# import zillow data\n",
    "zillow = pd.read_csv('input/Zip_MedianListingPrice_AllHomes.csv')\n",
    "zillow['postal_code'] = zillow['RegionName']\n",
    "zillow['postal_code'] = list(map(str,zillow.postal_code))\n",
    "# joins yelp & zillow data\n",
    "joined_yz = attributes_categories.merge(zillow, on='postal_code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Subset | by 5 most reviewed cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top cities merged with zillow\n",
    "top_star_cities_lst = joined.groupby('city').count().sort_values(by='name', ascending=False).head(5).index.tolist()\n",
    "city=joined.loc[joined['city'].isin(top_star_cities_lst)]\n",
    "#city['city_code'] = pd.Categorical(city.city)\n",
    "#city['city_code'] = city['city_code'].cat.codes\n",
    "city = city.reset_index(drop=True)\n",
    "city = city.merge(zillow, on='postal_code')\n",
    "city['median_home'] = city.iloc[:,172:-18].sum(axis=1) # by zip\n",
    "city['stars_'] = pd.cut(city.stars, bins=5, labels=range(1,6))\n",
    "city_color = city\n",
    "print('city_df shape: rows: {} columns: {}'.format(city.shape[0],city.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The yelp datasets span cities in North America and Europe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_it(joined ,1,3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "61 \"states\" are represented in the data set.  The states listed include terrorities. \n",
    "The reviews are distributed unevenly across the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,4))\n",
    "g = sns.countplot('state', data=joined, ax=ax)\n",
    "g.set_xticklabels(rotation=30, labels=joined.state)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 11 \"states\" that contain records over 1000.  There are five cities with over 10000 records.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(joined.groupby('state')['name'].count()).sort_values(by='name', ascending=False).rename(columns={'name':'count'}).head(20).T\n",
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "dfr=pd.DataFrame(joined.groupby('state')['state'].count()).rename(\n",
    "    columns={'state':'count'}).astype(int).reset_index().sort_values(by='count', ascending=False)\n",
    "sns.barplot(x='state', y='count',data = dfr[dfr['count'] > 1000], ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median star count varies between the states from 5 to 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_count = pd.DataFrame(joined.groupby('state')['stars'].mean()).sort_values(\n",
    "    by='stars', ascending=False)\n",
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "sns.barplot(x=\"state\", y=\"stars\", data=star_count.reset_index(), ci=68, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stars by City | counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of stars varies from city to city.  The 4 most frequently rated U.S. cities displayed varied distributions.  Las Vegas, Charlotte and Scottsdale have a particularly high count of 4 and 5 star ratings where Charlotte  has fewer 5 star ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_star_cities_lst.remove('Toronto')\n",
    "top_star_cities_lst.remove('Toronto')\n",
    "top_star_cities_df = joined.loc[joined['city'].isin(top_star_cities_lst)]\n",
    "g = sns.FacetGrid(top_star_cities_df, col=\"city\", col_wrap=5)\n",
    "g = g.map(plt.hist, \"stars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The geographic distribution of stars appear to be uniformly distributed across these cities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in top_star_cities_lst:\n",
    "    cen=2\n",
    "    df = city_color.loc[city_color.city.isin([i])]\n",
    "    # for las vegas  df = city[(city.latitude > 0) & (city.longitude < -100) & (city.latitude > 35) & (city.longitude > -116) ]\n",
    "    df1 = df[(df.latitude < df.latitude.mean() + df.latitude.std(0)) \n",
    "& (df.latitude >  df.latitude.mean() - df.latitude.std(0))\n",
    "& (df.longitude < df.longitude.mean() + cen*df.longitude.std(0))\n",
    "& (df.longitude >  df.longitude.mean() - cen*df.longitude.std(0))]\n",
    "    sns.lmplot( x=\"latitude\", y=\"longitude\", data=df1, fit_reg=False, \n",
    "           legend=True, size=5, aspect=2, hue='stars_', col = 'city', scatter_kws={'alpha':0.15});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stars appear to be geographically evenly distributed in each city when split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stars by city by location\n",
    "for i in top_star_cities_lst:\n",
    "    print(i)\n",
    "    cen=2\n",
    "    df = city_color.loc[city_color.city.isin([i])]\n",
    "    # for las vegas  df = city[(city.latitude > 0) & (city.longitude < -100) & (city.latitude > 35) & (city.longitude > -116) ]\n",
    "    df1 = df[(df.latitude < df.latitude.mean() + df.latitude.std(0)) \n",
    "& (df.latitude >  df.latitude.mean() - df.latitude.std(0))\n",
    "& (df.longitude < df.longitude.mean() + cen*df.longitude.std(0))\n",
    "& (df.longitude >  df.longitude.mean() - cen*df.longitude.std(0))]\n",
    "    \n",
    "    sns.lmplot( x=\"latitude\", y=\"longitude\", data=df1, fit_reg=False, \n",
    "           legend=True, size=4, aspect=1, hue='stars_', col = 'stars_', x_jitter=.5,col_wrap=5,scatter_kws={'alpha':0.15})\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by finding the best n for kmeans which varies slightly by city:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### identifying the right n for kmeans\n",
    "feature_lst = ['stars','review_count','median_home']\n",
    "for city_name in top_star_cities_lst:\n",
    "    print(city_name)\n",
    "    X = pre_process_by_city(city,city_name,feature_lst)\n",
    "    error = elbow_chart(X,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kmeans | by stars,review_count, median_home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_lst = ['stars','review_count','median_home']\n",
    "for city_name in top_star_cities_lst:\n",
    "    df = city_bbox(city,city_name)\n",
    "    df['klabels'],centers=city_clusters(df,city_name, feature_lst)\n",
    "    g = sns.lmplot( x=\"latitude\", y=\"longitude\", data=df, fit_reg=False, \n",
    "        legend=True, size=5, aspect=2, hue='klabels', col = 'city', scatter_kws={'alpha':0.15});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the klabels against the latitude and longitude for each city, several significant clusters emerge.  However on manual inspection of the business for each significant cluster, there does not appear to be an explicit pattern in the businesses for each cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kmeans | business attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for city_name in top_star_cities_lst:\n",
    "    df = city[city.city=='{}'.format(city_name)]\n",
    "    X = df[attribute_names]\n",
    "    pca = PCA(n_components=2)\n",
    "    principalComponents = pca.fit_transform(X)\n",
    "    kmeans = KMeans(n_clusters=4, random_state=0).fit(X)\n",
    "    principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['pc1', 'pc2'])\n",
    "    df['pc1'],df['pc2'] = principalDf['pc1'], principalDf['pc2'] \n",
    "    df['attr_labels'] =  kmeans.labels_\n",
    "    df = city_bbox(df, city_name)\n",
    "    sns.lmplot( x=\"latitude\", y=\"longitude\", data=df, fit_reg=False, \n",
    "        legend=True, size=5, aspect=2, hue='attr_labels', col = 'city', scatter_kws={'alpha':0.15});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to clustering based on stars, median income and review counts, on manual inspection of the business for each significant cluster, there does not appear to be an explicit pattern in the businesses for each cluster. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
