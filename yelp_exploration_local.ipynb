{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('input/yelp_review.csv', nrows=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a0e22e278>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0e0ff7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot('stars', data=reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, dev_data, train_labels, dev_labels = \\\n",
    "    train_test_split(reviews.text.values, reviews.stars.values, test_size=.1, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.63      0.66        94\n",
      "          2       0.38      0.30      0.33        87\n",
      "          3       0.38      0.30      0.34       175\n",
      "          4       0.46      0.51      0.49       300\n",
      "          5       0.61      0.66      0.64       344\n",
      "\n",
      "avg / total       0.51      0.52      0.51      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "train_dtm = cv.fit_transform(train_data)\n",
    "dev_dtm = cv.transform(dev_data)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_dtm, train_labels)\n",
    "\n",
    "print(metrics.classification_report(dev_labels, lr.predict(dev_dtm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30044"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.54      0.64        94\n",
      "          2       0.47      0.09      0.15        87\n",
      "          3       0.47      0.29      0.36       175\n",
      "          4       0.48      0.57      0.52       300\n",
      "          5       0.59      0.78      0.68       344\n",
      "\n",
      "avg / total       0.54      0.55      0.52      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tv = TfidfVectorizer(stop_words='english')\n",
    "train_dtm2 = tv.fit_transform(train_data)\n",
    "dev_dtm2 = tv.transform(dev_data)\n",
    "\n",
    "lr2 = LogisticRegression()\n",
    "lr2.fit(train_dtm2, train_labels)\n",
    "\n",
    "print(metrics.classification_report(dev_labels, lr2.predict(dev_dtm2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, an SVM is horrible if we use the count vectorizer but on par with logistic regression if we use the tf-idf vectorizer.  Fitting is also much faster with tf-idf as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.55      0.61        94\n",
      "          2       0.33      0.32      0.32        87\n",
      "          3       0.35      0.32      0.34       175\n",
      "          4       0.42      0.45      0.43       300\n",
      "          5       0.59      0.62      0.60       344\n",
      "\n",
      "avg / total       0.48      0.48      0.48      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC()\n",
    "svc.fit(train_dtm, train_labels)\n",
    "print(metrics.classification_report(dev_labels, svc.predict(dev_dtm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.65      0.66        94\n",
      "          2       0.38      0.24      0.30        87\n",
      "          3       0.38      0.33      0.35       175\n",
      "          4       0.45      0.50      0.47       300\n",
      "          5       0.62      0.68      0.65       344\n",
      "\n",
      "avg / total       0.51      0.52      0.52      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc2 = LinearSVC()\n",
    "svc2.fit(train_dtm2, train_labels)\n",
    "print(metrics.classification_report(dev_labels, svc2.predict(dev_dtm2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.17      0.25        94\n",
      "          2       0.21      0.05      0.08        87\n",
      "          3       0.28      0.29      0.28       175\n",
      "          4       0.33      0.29      0.31       300\n",
      "          5       0.42      0.62      0.50       344\n",
      "\n",
      "avg / total       0.36      0.37      0.34      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(train_dtm, train_labels)\n",
    "print(metrics.classification_report(dev_labels, knn.predict(dev_dtm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value of k is  {'n_neighbors': 5}\n",
      "Best score is 0.347\n"
     ]
    }
   ],
   "source": [
    "# Use GridSearchCV to optimize K with respect to weighted average f1\n",
    "k = {'n_neighbors': [1, 3, 5, 7, 10, 20]}\n",
    "knn = GridSearchCV(KNeighborsClassifier(), k, scoring = 'f1_weighted')\n",
    "knn.fit(train_dtm, train_labels)\n",
    "print(\"Best value of k is \", knn.best_params_)\n",
    "print(\"Best score is\", round(knn.best_score_,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.201342</td>\n",
       "      <td>0.114754</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.291115</td>\n",
       "      <td>0.482490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.284264</td>\n",
       "      <td>0.139860</td>\n",
       "      <td>0.272941</td>\n",
       "      <td>0.251101</td>\n",
       "      <td>0.499360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.283286</td>\n",
       "      <td>0.305506</td>\n",
       "      <td>0.502347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.261818</td>\n",
       "      <td>0.319109</td>\n",
       "      <td>0.534031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.165138</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.302583</td>\n",
       "      <td>0.536391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.131313</td>\n",
       "      <td>0.305284</td>\n",
       "      <td>0.541818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             1         2         3         4         5\n",
       "k                                                     \n",
       "1.0   0.201342  0.114754  0.256410  0.291115  0.482490\n",
       "3.0   0.284264  0.139860  0.272941  0.251101  0.499360\n",
       "5.0   0.253968  0.075472  0.283286  0.305506  0.502347\n",
       "7.0   0.240000  0.056604  0.261818  0.319109  0.534031\n",
       "10.0  0.165138  0.020833  0.208000  0.302583  0.536391\n",
       "20.0  0.061224  0.064516  0.131313  0.305284  0.541818"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check impact of tuning k on f1 score for individual star ratings\n",
    "\n",
    "k_test = [1,3,5,7,10,20]\n",
    "results = []\n",
    "for k in k_test:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(train_dtm, train_labels)\n",
    "    scores = np.append(k, metrics.f1_score(dev_labels, knn.predict(dev_dtm), average = None))\n",
    "    results.append(scores)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.columns = ['k','1','2','3','4','5']\n",
    "df.set_index('k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing k generally reduces f1 score for low ratings (1 to 3 stars) while increasing it for 5 start reviews. Since there are more 5 star reviews than any other, this may indicate that with high k we start underfitting and predict 5's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try KNN using tf-idf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.39      0.44        94\n",
      "          2       0.25      0.13      0.17        87\n",
      "          3       0.25      0.34      0.29       175\n",
      "          4       0.36      0.39      0.37       300\n",
      "          5       0.53      0.51      0.52       344\n",
      "\n",
      "avg / total       0.40      0.40      0.40      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn2 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn2.fit(train_dtm2, train_labels)\n",
    "print(metrics.classification_report(dev_labels, knn2.predict(dev_dtm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
